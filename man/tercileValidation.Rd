% Generated by roxygen2 (4.0.1): do not edit by hand
\name{tercileValidation}
\alias{tercileValidation}
\title{Tercile plot for visualization of the skill of an ensemble forecast prediction}
\usage{
tercileValidation(mm.obj, obs, stationId = NULL, color.pal = c("ypb",
  "reds"))
}
\arguments{
\item{mm.obj}{A multi-member object, either a field or a multi-member station object as a result of
downscaling of a forecast using station data. See details.}

\item{obs}{The benchmarking observations for forecast verification}

\item{stationId}{In case of multimember multistation objects, one station can be selected to plot
the diagram. Otherwise ignored.}

\item{color.pal}{Color palette for the representation of the probabilities. Default to \code{"ypb"} (yellow-pink-blue),
 suitable for the visualization in black and white printing devices. \code{"reds"} for a white-red transition.}
}
\description{
Tercile plot for the visualization of the skill of an ensemble forecast prediction.
}
\details{
For each member, the daily predictions are averaged to obtain a single seasonal forecast. For
rectangular spatial domains (i.e., for fields), the spatial average is first computed (with a warning) to obtain a
unique series for the whole domain. The corresponding terciles for each ensemble member are then computed
for the analysis period. Thus, data is converted converted to a series of tercile categories by considering values
 above, between or below the terciles of the whole period. The probability of a member to fall into the observed tercile
 is represented by the colorbar. For instance, probabilities below 1/3 are very low, indicating that a minority of the members
 falls in the tercile. Conversely, probabilities above 2/3 indicate a high level of member agreement (more than 66\% of members
 falling in the same tercile). The observed terciles (the events that actually occurred) are represented by the white circles.

 Finally, the ROC Skill Score (ROCSS) is indicated in the secondary (right) Y axis. For each tercile, it provides a
 quantitative measure of the forecast skill, and it is commonly used to evaluate the performance of probabilistic systems
 (Joliffe and Stephenson 2003). The value of this score ranges from 1 (perfect forecast system) to -1
 (perfectly bad forecast system). A value zero indicates no skill compared with a random prediction.

 In case of multimember fields, the field is spatially averaged to obtain one single time series
 for each member prior to data analysis, with a warning. In case of multimember stations, one single station
 can be selected through the \code{stationId} argument, otherwise all station series are also averaged.
}
\note{
The computation of climatological terciles requires a representative period to obtain meaningful results.
}
\author{
J. Bedia \email{joaquin.bedia@gmail.com}, M.D. Frias and J, Fernandez based on the original diagram
conceived by A. Cofino.
}
\references{
Diez, E., Orfila, B., Frias, M.D., Fernandez, J., Cofino, A.S., Gutierrez, J.M., 2011.
Downscaling ECMWF seasonal precipitation forecasts in Europe using the RCA model.
 Tellus A 63, 757-762. doi:10.1111/j.1600-0870.2011.00523.x

 Jolliffe, I. T. and Stephenson, D. B. 2003. Forecast Verification: A Practitioner's Guide in
 Atmospheric Science, Wiley, NY
}

